import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import os
import matplotlib.font_manager as fm

# ==========================================
# 0. í•œê¸€ í°íŠ¸ ì„¤ì • (ê°€ì¥ ìµœìƒë‹¨ ì‹¤í–‰)
# ==========================================
font_file = "NanumGothic-Regular.ttf"
font_path = os.path.join(os.getcwd(), font_file)

if os.path.exists(font_path):
    # Matplotlibì— í°íŠ¸ ì¶”ê°€ ë° ì„¤ì •
    fm.fontManager.addfont(font_path)
    font_name = fm.FontProperties(fname=font_path).get_name()
    plt.rc('font', family=font_name)
    plt.rcParams['axes.unicode_minus'] = False
    # Seaborn í°íŠ¸ ê°•ì œ ì„¤ì •
    sns.set(font=font_name, rc={'axes.unicode_minus': False}, style='whitegrid')
    font_msg = f"âœ… í•œê¸€ í°íŠ¸('{font_name}')ê°€ ì„±ê³µì ìœ¼ë¡œ ì ìš©ë˜ì—ˆìŠµë‹ˆë‹¤."
else:
    font_msg = "âš ï¸ 'NanumGothic-Regular.ttf' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ì–´ í•œê¸€ì´ ê¹¨ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤."

# ëª¨ë¸ë§ ê´€ë ¨ ë¼ì´ë¸ŒëŸ¬ë¦¬
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.impute import SimpleImputer
from sklearn.tree import DecisionTreeClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, roc_curve, auc, confusion_matrix
from sklearn.feature_selection import SequentialFeatureSelector

try:
    from imblearn.over_sampling import SMOTE
    has_smote = True
except ImportError:
    has_smote = False

# ì•± ì„¤ì •
st.set_page_config(page_title="ê³ ê° ì´íƒˆ ì˜ˆì¸¡ ë¶„ì„", layout="wide")
st.sidebar.info(font_msg)
st.title("ğŸ“Š ê³ ê° ì´íƒˆ ê´€ë¦¬ ë°ì´í„° ë¶„ì„ ì•±")

# 1. ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
@st.cache_data
def load_data():
    return pd.read_csv("Churn_management.csv")

try:
    df = load_data()
    st.success("ë°ì´í„° ë¡œë“œ ì™„ë£Œ!")
except:
    st.error("'Churn_management.csv' íŒŒì¼ì´ í•„ìš”í•©ë‹ˆë‹¤.")
    st.stop()

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if 'processed_data' not in st.session_state:
    st.session_state.processed_data = None

# ==========================================
# 1. ë°ì´í„° ë¶„ì„ ë° ì‹œê°í™”
# ==========================================
st.header("1. ë°ì´í„° ë¶„ì„ ë° ì‹œê°í™”")

col_dist, col_custom = st.columns([1, 2])

with col_dist:
    st.subheader("ì¢…ì† ë³€ìˆ˜(Exited) ë¶„í¬")
    fig, ax = plt.subplots(figsize=(5, 4))
    sns.countplot(x='Exited', data=df, ax=ax, palette='viridis')
    ax.set_title("ê³ ê° ì´íƒˆ ì—¬ë¶€ ë¶„í¬")
    ax.set_xlabel("ì´íƒˆ ì—¬ë¶€ (0:ìœ ì§€, 1:ì´íƒˆ)")
    ax.set_ylabel("ê³ ê° ìˆ˜")
    st.pyplot(fig)

with col_custom:
    st.subheader("ë³€ìˆ˜ë³„ ìƒì„¸ ì‹œê°í™”")
    c1, c2, c3 = st.columns(3)
    p_type = c1.selectbox("ê·¸ë˜í”„ ìœ í˜•", ["íˆìŠ¤í† ê·¸ë¨", "ë°•ìŠ¤ í”Œë¡¯", "ì‚°ì ë„", "ë§‰ëŒ€ ì°¨íŠ¸", "ì„  ì°¨íŠ¸"])
    x_v = c2.selectbox("Xì¶• ë³€ìˆ˜ ì„ íƒ", df.columns)
    y_v = c3.selectbox("Yì¶• ë³€ìˆ˜ ì„ íƒ (ì˜µì…˜)", [None] + list(df.columns))

    fig2, ax2 = plt.subplots(figsize=(8, 5))
    try:
        if p_type == "íˆìŠ¤í† ê·¸ë¨":
            sns.histplot(data=df, x=x_v, kde=True, ax=ax2)
        elif p_type == "ë°•ìŠ¤ í”Œë¡¯":
            sns.boxplot(data=df, x=x_v, y=y_v, ax=ax2)
        elif p_type == "ì‚°ì ë„":
            if y_v: sns.scatterplot(data=df, x=x_v, y=y_v, hue='Exited', ax=ax2)
            else: st.warning("ì‚°ì ë„ëŠ” Yì¶• ë³€ìˆ˜ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
        elif p_type == "ë§‰ëŒ€ ì°¨íŠ¸":
            if y_v: sns.barplot(data=df, x=x_v, y=y_v, ax=ax2)
            else: sns.countplot(data=df, x=x_v, ax=ax2)
        elif p_type == "ì„  ì°¨íŠ¸":
            if y_v: sns.lineplot(data=df, x=x_v, y=y_v, ax=ax2)
            else: st.warning("ì„  ì°¨íŠ¸ëŠ” Yì¶• ë³€ìˆ˜ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
        
        ax2.set_title(f"{x_v}ì— ëŒ€í•œ {p_type}")
        st.pyplot(fig2)
    except Exception as e:
        st.error(f"ì‹œê°í™” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

# ==========================================
# 2. ë°ì´í„° ì „ì²˜ë¦¬ (ì†ë„ ìµœì í™” ë²„ì „)
# ==========================================
st.header("2. ë°ì´í„° ì „ì²˜ë¦¬")

if st.button("ë°ì´í„° ì „ì²˜ë¦¬ ì‹¤í–‰"):
    with st.spinner("16ë§Œ ê±´ ë°ì´í„° ì²˜ë¦¬ ë° ë³€ìˆ˜ ì„ íƒ ì¤‘... (ì•½ 10~20ì´ˆ ì†Œìš”)"):
        prog = st.empty()
        df_p = df.copy()

        # 1. ì‹ë³„ì ì œê±°
        prog.text("ì§„í–‰ì¤‘: ì‹ë³„ì ì»¬ëŸ¼ ì œê±°...")
        df_p = df_p.drop(columns=[c for c in ['id', 'CustomerId', 'Surname'] if c in df_p.columns])
        
        # 2. ê²°ì¸¡ì¹˜ ë° ì´ìƒì¹˜ (ë²¡í„° ì—°ì‚° ìµœì í™”)
        prog.text("ì§„í–‰ì¤‘: ê²°ì¸¡ì¹˜ ë° ì´ìƒì¹˜ ì²˜ë¦¬...")
        nums = df_p.select_dtypes(include=[np.number]).columns.drop('Exited', errors='ignore')
        cats = df_p.select_dtypes(include=['object']).columns
        
        # ê²°ì¸¡ì¹˜ëŠ” í‰ê· /ìµœë¹ˆê°’ìœ¼ë¡œ
        df_p[nums] = df_p[nums].fillna(df_p[nums].mean())
        for c in cats:
            df_p[c] = df_p[c].fillna(df_p[c].mode()[0])

        # ì´ìƒì¹˜ëŠ” IQRë¡œ í•˜í•œ/ìƒí•œ ì¡°ì •(Clipping)
        for c in nums:
            q1, q3 = df_p[c].quantile([0.25, 0.75])
            iqr = q3 - q1
            df_p[c] = np.clip(df_p[c], q1 - 1.5*iqr, q3 + 1.5*iqr)

        # 3. ì›í•« ì¸ì½”ë”© ë° ìŠ¤ì¼€ì¼ë§
        prog.text("ì§„í–‰ì¤‘: íŠ¹ì„± ê³µí•™ ì ìš©...")
        df_p = pd.get_dummies(df_p, columns=cats, drop_first=True)
        sc = StandardScaler()
        scale_cols = [c for c in df_p.columns if c != 'Exited']
        df_p[scale_cols] = sc.fit_transform(df_p[scale_cols])

        X, y = df_p.drop('Exited', axis=1), df_p['Exited']

        # 4. í´ë˜ìŠ¤ ë¶ˆê· í˜• ì²˜ë¦¬ (SMOTE)
        if has_smote:
            prog.text("ì§„í–‰ì¤‘: ë°ì´í„° ë¶ˆê· í˜• ì¡°ì •(SMOTE)...")
            X, y = SMOTE(random_state=42).fit_resample(X, y)
        
        # 5. ë³€ìˆ˜ ì„ íƒ (ìƒ˜í”Œë§ìœ¼ë¡œ ì†ë„ ìµœì í™”)
        prog.text("ì§„í–‰ì¤‘: í•µì‹¬ ë³€ìˆ˜ ì¶”ì¶œ(Stepwise Selection)...")
        # ì „ì²´ ë°ì´í„° ëŒ€ì‹  5000ê±´ ìƒ˜í”Œë¡œ ì¤‘ìš” ë³€ìˆ˜ íŒë‹¨
        sample_X = X.sample(n=min(5000, len(X)), random_state=42)
        sample_y = y.loc[sample_X.index]
        sfs = SequentialFeatureSelector(LogisticRegression(max_iter=100), n_features_to_select='auto').fit(sample_X, sample_y)
        X = X[X.columns[sfs.get_support()]]
        
        st.session_state.processed_data = {'X': X, 'y': y}
        prog.empty()
        st.success(f"âœ… ì „ì²˜ë¦¬ ì™„ë£Œ! (ì„ íƒëœ ë³€ìˆ˜: {list(X.columns)})")

# ==========================================
# 3. ë°ì´í„° ë‚˜ëˆ„ê¸° ë° ëª¨ë¸ ì„¤ì •
# ==========================================
st.header("3. ë°ì´í„° ë‚˜ëˆ„ê¸° ë° ëª¨ë¸ ì„¤ì •")

if st.session_state.processed_data is not None:
    X, y = st.session_state.processed_data['X'], st.session_state.processed_data['y']

    col_split, col_opt = st.columns(2)
    with col_split:
        ratio = st.radio("ë°ì´í„° ë¶„í•  ë¹„ìœ¨", ["7:3", "8:2"], horizontal=True)
        test_size = 0.3 if ratio == "7:3" else 0.2
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42)
    
    with col_opt:
        dt_d = st.slider("ì˜ì‚¬ê²°ì •ë‚˜ë¬´ ê¹Šì´", 1, 20, 5)
        lr_c = st.slider("ë¡œì§€ìŠ¤í‹± ê·œì œ(C)", 0.01, 10.0, 1.0)

    if st.button("ëª¨ë¸ í•™ìŠµ ë° í‰ê°€ ì‹œì‘"):
        # í‰ê°€ í•¨ìˆ˜
        def evaluate(model, X_t, y_t, name):
            pred = model.predict(X_t)
            prob = model.predict_proba(X_t)[:, 1]
            
            st.subheader(f"[{name}] í‰ê°€ ê²°ê³¼")
            m1, m2, m3, m4 = st.columns(4)
            m1.metric("ì •í™•ë„", f"{accuracy_score(y_t, pred):.2f}")
            m2.metric("ì •ë°€ë„", f"{precision_score(y_t, pred):.2f}")
            m3.metric("ì¬í˜„ìœ¨", f"{recall_score(y_t, pred):.2f}")
            m4.metric("F1-Score", f"{f1_score(y_t, pred):.2f}")

            c1, c2 = st.columns(2)
            with c1:
                cm = confusion_matrix(y_t, pred)
                fig_cm, ax_cm = plt.subplots()
                sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax_cm)
                ax_cm.set_title(f"{name} í˜¼ë™ í–‰ë ¬")
                st.pyplot(fig_cm)
            with c2:
                fpr, tpr, _ = roc_curve(y_t, prob)
                fig_roc, ax_roc = plt.subplots()
                ax_roc.plot(fpr, tpr, label=f'AUC = {auc(fpr, tpr):.2f}')
                ax_roc.plot([0, 1], [0, 1], '--')
                ax_roc.set_title(f"{name} ROC ì»¤ë¸Œ")
                ax_roc.legend()
                st.pyplot(fig_roc)

        # 4. ì˜ì‚¬ê²°ì •ë‚˜ë¬´
        st.divider()
        st.header("4. ëª¨ë¸ í‰ê°€(ì˜ì‚¬ê²°ì •ë‚˜ë¬´)")
        dt = DecisionTreeClassifier(max_depth=dt_d, random_state=42).fit(X_train, y_train)
        evaluate(dt, X_test, y_test, "ì˜ì‚¬ê²°ì •ë‚˜ë¬´")

        # 5. ë¡œì§“ ëª¨ë¸
        st.divider()
        st.header("5. ëª¨ë¸ í‰ê°€(ë¡œì§“ ëª¨ë¸)")
        lr = LogisticRegression(C=lr_c, max_iter=1000, random_state=42).fit(X_train, y_train)
        evaluate(lr, X_test, y_test, "ë¡œì§€ìŠ¤í‹± íšŒê·€")
else:
    st.info("ë¨¼ì € ì „ì²˜ë¦¬ ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”.")
