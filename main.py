import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import os
import platform
import matplotlib.font_manager as fm
import platform

# í°íŠ¸ ì„¤ì • í•¨ìˆ˜
def set_korean_font():
    # 1. ì—…ë¡œë“œí•œ í°íŠ¸ íŒŒì¼ ì´ë¦„ (ì •í™•í•´ì•¼ í•¨)
    font_file = "NanumGothic-Regular.ttf"
    font_path = os.path.join(os.getcwd(), font_file)
    
    if os.path.exists(font_path):
        # 2. í°íŠ¸ ë§¤ë‹ˆì €ì— í°íŠ¸ ì¶”ê°€
        font_bin = fm.FontEntry(
            fname=font_path, 
            name='NanumGothic' # ì‚¬ìš©í•  ì´ë¦„ ì„¤ì •
        )
        fm.fontManager.ttflist.insert(0, font_bin)
        
        # 3. Matplotlib ê¸°ë³¸ ì„¤ì •ì— ì ìš©
        plt.rc('font', family='NanumGothic')
        
        # 4. ë§ˆì´ë„ˆìŠ¤ ê¸°í˜¸ê°€ ê¹¨ì§€ëŠ” í˜„ìƒ ë°©ì§€
        plt.rcParams['axes.unicode_minus'] = False
        return True
    else:
        st.error(f"í°íŠ¸ íŒŒì¼ '{font_file}'ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. GitHubì— íŒŒì¼ì„ ì—…ë¡œë“œí–ˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
        return False

# í°íŠ¸ ì„¤ì • ì‹¤í–‰
set_korean_font()
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.impute import SimpleImputer
from sklearn.tree import DecisionTreeClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, roc_curve, auc, confusion_matrix
from sklearn.feature_selection import SequentialFeatureSelector

# SMOTE ë¼ì´ë¸ŒëŸ¬ë¦¬ í™•ì¸ (ë¶ˆê· í˜• ë°ì´í„° ì²˜ë¦¬)
try:
    from imblearn.over_sampling import SMOTE
    has_smote = True
except ImportError:
    has_smote = False
    st.warning("imbalanced-learn ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. SMOTE ê¸°ëŠ¥ì€ ê±´ë„ˆëœë‹ˆë‹¤. (ì„¤ì¹˜ ëª…ë ¹ì–´: pip install imbalanced-learn)")

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="ê³ ê° ì´íƒˆ ì˜ˆì¸¡ ì•±", layout="wide")

# ì œëª©
st.title("ğŸ“Š ê³ ê° ì´íƒˆ ê´€ë¦¬ ë°ì´í„° ë¶„ì„ ì•±")

# 1. ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
@st.cache_data
def load_data():
    # íŒŒì¼ì´ ê°™ì€ ë””ë ‰í† ë¦¬ì— ìˆë‹¤ê³  ê°€ì •
    df = pd.read_csv("Churn_management.csv")
    return df

try:
    df = load_data()
    st.success("ë°ì´í„°ë¥¼ ì„±ê³µì ìœ¼ë¡œ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤!")
except FileNotFoundError:
    st.error("'Churn_management.csv' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê°™ì€ í´ë”ì— ìœ„ì¹˜ì‹œì¼œ ì£¼ì„¸ìš”.")
    st.stop()

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” (ì „ì²˜ë¦¬ëœ ë°ì´í„° ì €ì¥ìš©)
if 'processed_data' not in st.session_state:
    st.session_state.processed_data = None
if 'X_train' not in st.session_state:
    st.session_state.X_train = None

# ==========================================
# 1. ë°ì´í„° ë¶„ì„ ë° ì‹œê°í™”
# ==========================================
st.header("1. ë°ì´í„° ë¶„ì„ ë° ì‹œê°í™”")

# ì›ë³¸ ë°ì´í„° ë³´ê¸°
if st.checkbox("ì›ë³¸ ë°ì´í„° ë³´ê¸°"):
    st.dataframe(df.head())

# ì¢…ì† ë³€ìˆ˜ ë¶„í¬ í™•ì¸
st.subheader("ì¢…ì† ë³€ìˆ˜ ë¶„í¬ (ì´íƒˆ ì—¬ë¶€: Exited)")
fig_target, ax_target = plt.subplots(figsize=(6, 4))
sns.countplot(x='Exited', data=df, ax=ax_target, palette='viridis')
ax_target.set_title("ì´íƒˆ ì—¬ë¶€ ë¶„í¬ (0: ìœ ì§€, 1: ì´íƒˆ)")
st.pyplot(fig_target)

# ì¸í„°ë™í‹°ë¸Œ ì‹œê°í™”
st.subheader("ë³€ìˆ˜ë³„ ì‹œê°í™”")
col1, col2, col3 = st.columns(3)

with col1:
    plot_type = st.selectbox("ê·¸ë˜í”„ ìœ í˜• ì„ íƒ", ["íˆìŠ¤í† ê·¸ë¨", "ë°•ìŠ¤ í”Œë¡¯", "ì‚°ì ë„", "ë§‰ëŒ€ ì°¨íŠ¸", "ì„  ì°¨íŠ¸"])
with col2:
    x_var = st.selectbox("Xì¶• ë³€ìˆ˜ ì„ íƒ", df.columns)
with col3:
    y_var = st.selectbox("Yì¶• ë³€ìˆ˜ ì„ íƒ (íˆìŠ¤í† ê·¸ë¨/ë°•ìŠ¤í”Œë¡¯ì€ ì„ íƒ ì‚¬í•­)", [None] + list(df.columns))

fig_custom, ax_custom = plt.subplots(figsize=(8, 5))

try:
    if plot_type == "íˆìŠ¤í† ê·¸ë¨":
        sns.histplot(data=df, x=x_var, kde=True, ax=ax_custom)
    elif plot_type == "ë°•ìŠ¤ í”Œë¡¯":
        sns.boxplot(data=df, x=x_var, y=y_var, ax=ax_custom)
    elif plot_type == "ì‚°ì ë„":
        if y_var:
            sns.scatterplot(data=df, x=x_var, y=y_var, hue='Exited', ax=ax_custom)
        else:
            st.warning("ì‚°ì ë„ë¥¼ ê·¸ë¦¬ë ¤ë©´ Yì¶• ë³€ìˆ˜ë¥¼ ì„ íƒí•´ì•¼ í•©ë‹ˆë‹¤.")
    elif plot_type == "ë§‰ëŒ€ ì°¨íŠ¸":
        if y_var:
            sns.barplot(data=df, x=x_var, y=y_var, ax=ax_custom)
        else:
            sns.countplot(data=df, x=x_var, ax=ax_custom)
    elif plot_type == "ì„  ì°¨íŠ¸":
        if y_var:
            sns.lineplot(data=df, x=x_var, y=y_var, ax=ax_custom)
        else:
            st.warning("ì„  ì°¨íŠ¸ë¥¼ ê·¸ë¦¬ë ¤ë©´ Yì¶• ë³€ìˆ˜ë¥¼ ì„ íƒí•´ì•¼ í•©ë‹ˆë‹¤.")
    
    st.pyplot(fig_custom)
except Exception as e:
    st.error(f"ê·¸ë˜í”„ë¥¼ ê·¸ë¦¬ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")


# ==========================================
# 2. ë°ì´í„° ì „ì²˜ë¦¬
# ==========================================
st.header("2. ë°ì´í„° ì „ì²˜ë¦¬")

if st.button("ë°ì´í„° ì „ì²˜ë¦¬ ì‹¤í–‰"):
    with st.spinner("ë°ì´í„° ì „ì²˜ë¦¬ ì¤‘..."):
        # ìƒíƒœ ë©”ì‹œì§€ë¥¼ ìœ„í•œ ë¹ˆ ê³µê°„
        status = st.empty()
        
        df_processed = df.copy()

        # 1. ë¶ˆí•„ìš”í•œ ì‹ë³„ì ì»¬ëŸ¼ ì œê±°
        status.text("1/6: ë¶ˆí•„ìš”í•œ ì»¬ëŸ¼ ì œê±° ì¤‘...")
        drop_cols = ['id', 'CustomerId', 'Surname']
        df_processed = df_processed.drop(columns=[c for c in drop_cols if c in df_processed.columns])
        
        # 2. ê²°ì¸¡ì¹˜ ë° ì´ìƒì¹˜ ì²˜ë¦¬ (ë²¡í„° ì—°ì‚°ìœ¼ë¡œ ìµœì í™”)
        status.text("2/6: ê²°ì¸¡ì¹˜ ë° ì´ìƒì¹˜ ì²˜ë¦¬ ì¤‘...")
        num_cols = df_processed.select_dtypes(include=['float64', 'int64']).columns.drop('Exited', errors='ignore')
        cat_cols = df_processed.select_dtypes(include=['object']).columns
        
        # ê²°ì¸¡ì¹˜ ì±„ìš°ê¸°
        df_processed[num_cols] = df_processed[num_cols].fillna(df_processed[num_cols].mean())
        for col in cat_cols:
            df_processed[col] = df_processed[col].fillna(df_processed[col].mode()[0])

        # ì´ìƒì¹˜ ì²˜ë¦¬ (IQR Clipping)
        for col in num_cols:
            Q1 = df_processed[col].quantile(0.25)
            Q3 = df_processed[col].quantile(0.75)
            IQR = Q3 - Q1
            df_processed[col] = np.clip(df_processed[col], Q1 - 1.5 * IQR, Q3 + 1.5 * IQR)

        # 3. ì›-í•« ì¸ì½”ë”© ë° ìŠ¤ì¼€ì¼ë§
        status.text("3/6: ì¸ì½”ë”© ë° ìŠ¤ì¼€ì¼ë§ ì ìš© ì¤‘...")
        df_processed = pd.get_dummies(df_processed, columns=cat_cols, drop_first=True)
        
        scaler = StandardScaler()
        cols_to_scale = [c for c in df_processed.columns if c != 'Exited']
        df_processed[cols_to_scale] = scaler.fit_transform(df_processed[cols_to_scale])

        X = df_processed.drop('Exited', axis=1)
        y = df_processed['Exited']

        # 4. í´ë˜ìŠ¤ ë¶ˆê· í˜• ì²˜ë¦¬ (SMOTE)
        status.text("4/6: í´ë˜ìŠ¤ ë¶ˆê· í˜• ì²˜ë¦¬(SMOTE) ì¤‘... (ì‹œê°„ ì†Œìš” ê°€ëŠ¥)")
        if has_smote:
            smote = SMOTE(random_state=42)
            X, y = smote.fit_resample(X, y)
        
        # 5. ë‹¨ê³„ì  ì„ íƒë²• (Stepwise Selection) - â˜…ì†ë„ ìµœì í™” í¬ì¸íŠ¸â˜…
        status.text("5/6: ë³€ìˆ˜ ì„ íƒ ì¤‘ (ìƒ˜í”Œë§ ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ ì†ë„ ìµœì í™”)...")
        
        # ë°ì´í„°ê°€ ë„ˆë¬´ ë§ìœ¼ë¯€ë¡œ ë³€ìˆ˜ ì„ íƒ ì‹œì—ëŠ” 5,000ê±´ë§Œ ìƒ˜í”Œë§í•˜ì—¬ ê³„ì‚° (ê²°ê³¼ëŠ” ìœ ì‚¬í•¨)
        sample_size = min(5000, len(X))
        X_sample = X.sample(n=sample_size, random_state=42)
        y_sample = y.loc[X_sample.index]

        sfs = SequentialFeatureSelector(
            LogisticRegression(max_iter=100), 
            n_features_to_select='auto', 
            direction='forward'
        )
        sfs.fit(X_sample, y_sample)
        selected_features = X.columns[sfs.get_support()]
        X = X[selected_features]
        
        # 6. ì™„ë£Œ ë° ì €ì¥
        status.text("6/6: ëª¨ë“  ì „ì²˜ë¦¬ ì™„ë£Œ!")
        st.session_state.processed_data = {'X': X, 'y': y}
        
        st.success("âœ… ì „ì²˜ë¦¬ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
        st.write(f"**ì„ íƒëœ í•µì‹¬ ë³€ìˆ˜:** {list(selected_features)}")
        st.write(f"**ìµœì¢… ë°ì´í„° í¬ê¸°:** {X.shape}")
        


# ==========================================
# 3. ë°ì´í„° ë¶„í•  ë° ëª¨ë¸ ì„¤ì •
# ==========================================
st.header("3. ë°ì´í„° ë¶„í•  ë° ëª¨ë¸ ì„¤ì •")

if st.session_state.processed_data is not None:
    X = st.session_state.processed_data['X']
    y = st.session_state.processed_data['y']

    # ë¶„í•  ë¹„ìœ¨ ì„ íƒ
    split_ratio = st.radio("í•™ìŠµ/í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¶„í•  ë¹„ìœ¨ ì„ íƒ", ["7:3", "8:2"])
    test_size = 0.3 if split_ratio == "7:3" else 0.2

    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42)

    col_dt, col_log = st.columns(2)

    with col_dt:
        st.subheader("ì˜ì‚¬ê²°ì •ë‚˜ë¬´(Decision Tree) ì˜µì…˜")
        dt_max_depth = st.slider("ìµœëŒ€ ê¹Šì´ (Max Depth)", 1, 20, 5)
        dt_criterion = st.selectbox("ë¶„í•  ê¸°ì¤€ (Criterion)", ["gini", "entropy"])

    with col_log:
        st.subheader("ë¡œì§€ìŠ¤í‹± íšŒê·€(Logistic Regression) ì˜µì…˜")
        lr_C = st.slider("C ê°’ (ê·œì œ ê°•ë„ì˜ ì—­ìˆ˜)", 0.01, 10.0, 1.0)
        lr_max_iter = st.number_input("ìµœëŒ€ ë°˜ë³µ íšŸìˆ˜ (Max Iterations)", value=500)

    # í•™ìŠµ ë° í‰ê°€ ë²„íŠ¼
    if st.button("ëª¨ë¸ í•™ìŠµ ë° í‰ê°€"):
        
        # í‰ê°€ì§€í‘œ ì¶œë ¥ í—¬í¼ í•¨ìˆ˜
        def show_metrics(y_true, y_pred, y_prob, title):
            acc = accuracy_score(y_true, y_pred)
            prec = precision_score(y_true, y_pred)
            rec = recall_score(y_true, y_pred)
            f1 = f1_score(y_true, y_pred)
            
            st.markdown(f"### **{title} í‰ê°€ ì§€í‘œ**")
            m1, m2, m3, m4 = st.columns(4)
            m1.metric("ì •í™•ë„ (Accuracy)", f"{acc:.2f}")
            m2.metric("ì •ë°€ë„ (Precision)", f"{prec:.2f}")
            m3.metric("ì¬í˜„ìœ¨ (Recall)", f"{rec:.2f}")
            m4.metric("F1 ì ìˆ˜", f"{f1:.2f}")

            # ê·¸ë˜í”„ ì¶œë ¥
            c1, c2 = st.columns(2)
            
            # Confusion Matrix
            with c1:
                st.write("**í˜¼ë™ í–‰ë ¬ (Confusion Matrix)**")
                cm = confusion_matrix(y_true, y_pred)
                fig_cm, ax_cm = plt.subplots()
                sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax_cm)
                ax_cm.set_xlabel("ì˜ˆì¸¡ê°’")
                ax_cm.set_ylabel("ì‹¤ì œê°’")
                st.pyplot(fig_cm)
            
            # ROC Curve
            with c2:
                st.write("**ROC ê³¡ì„ **")
                fpr, tpr, _ = roc_curve(y_true, y_prob)
                roc_auc = auc(fpr, tpr)
                fig_roc, ax_roc = plt.subplots()
                ax_roc.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')
                ax_roc.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
                ax_roc.set_xlim([0.0, 1.0])
                ax_roc.set_ylim([0.0, 1.05])
                ax_roc.set_xlabel('False Positive Rate (ìœ„ì–‘ì„±ë¥ )')
                ax_roc.set_ylabel('True Positive Rate (ì§„ì–‘ì„±ë¥ )')
                ax_roc.legend(loc="lower right")
                st.pyplot(fig_roc)

        # ==========================================
        # 4. ëª¨ë¸ í‰ê°€ (ì˜ì‚¬ê²°ì •ë‚˜ë¬´)
        # ==========================================
        st.header("4. ëª¨ë¸ í‰ê°€ - ì˜ì‚¬ê²°ì •ë‚˜ë¬´")
        dt_model = DecisionTreeClassifier(max_depth=dt_max_depth, criterion=dt_criterion, random_state=42)
        dt_model.fit(X_train, y_train)
        y_pred_dt = dt_model.predict(X_test)
        y_prob_dt = dt_model.predict_proba(X_test)[:, 1]
        
        show_metrics(y_test, y_pred_dt, y_prob_dt, "ì˜ì‚¬ê²°ì •ë‚˜ë¬´")

        st.markdown("---") # êµ¬ë¶„ì„ 

        # ==========================================
        # 5. ëª¨ë¸ í‰ê°€ (ë¡œì§“ ëª¨ë¸)
        # ==========================================
        st.header("5. ëª¨ë¸ í‰ê°€ - ë¡œì§€ìŠ¤í‹± íšŒê·€")
        lr_model = LogisticRegression(C=lr_C, max_iter=int(lr_max_iter), random_state=42)
        lr_model.fit(X_train, y_train)
        y_pred_lr = lr_model.predict(X_test)
        y_prob_lr = lr_model.predict_proba(X_test)[:, 1]

        show_metrics(y_test, y_pred_lr, y_prob_lr, "ë¡œì§€ìŠ¤í‹± íšŒê·€")

else:
    st.info("ğŸ‘† ë¨¼ì € 2ë²ˆ ì„¹ì…˜ì˜ 'ë°ì´í„° ì „ì²˜ë¦¬ ì‹¤í–‰' ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”.")
